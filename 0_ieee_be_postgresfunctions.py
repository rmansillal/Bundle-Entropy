# -*- coding: utf-8 -*-
"""0_IEEE_BE_PostgresFunctions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zBE4DpumMtQKRk3yYY2QOiGS7WUnVSEe

# *Mansilla, R., Smith, G., Smith A. and Goulding, J. "Bundle entropy as an optimized measure of consumers' systematic product choice combinations in mass transactional data". In 2022 IEEE International Conference on Big Data (IEEE Big Data 2022), Osaka, Japan.*
-----

# **Code to replicate all entropy-based aggregate functions in Postgres**
All measure are in their noirmalized version.

## 1 *Bundle Entropy (BE)*

The proposed *Bundle Entropy* (formula 9 in the paper) is implemented as a custom postgres aggregrate function. The implementation (copy and paste into psql to install) is:
```
create extension plpython3u;
 
CREATE TYPE basket_tuple AS (
   basket_id       TEXT,
   item       TEXT
);

CREATE OR REPLACE FUNCTION _state_bundle_entropy( prev basket_tuple[], basket_id TEXT, item TEXT)
   RETURNS basket_tuple[] AS
$$
   SELECT array_append(prev, (basket_id, item)::basket_tuple);
$$
LANGUAGE 'sql' IMMUTABLE;


CREATE OR REPLACE FUNCTION _final_bev3_norm(list_in basket_tuple[])
   RETURNS NUMERIC AS
$$
 
import pandas as pd
import numpy as np
from collections import defaultdict
from collections import Counter
 
data = defaultdict(list)
for record in list_in:
    data[record['basket_id']].append( record['item'] )
 
dataset = [ v for k, v in data.items() ]
 
baskets = [ frozenset(b) for b in dataset ]
 
if len(baskets) == 1:
    return 0 # degenerate case
 
unique_baskets = Counter(baskets)
 
out = []
for b1 in unique_baskets.keys():
   r_b1 = 0
   for b2 in baskets:
       r_b1 += 1 -  ( max(len(b1 - b2), len(b2 - b1)) / max(len(b1),len(b2)) )
     
   r_b1 /= len(baskets)
 
   out.append( ( r_b1, unique_baskets[b1] ))
rtn = 0
for b1p in out:
 
   rtn += (b1p[1]/len(baskets) ) * np.log2(b1p[0])
 
 
return -(rtn / np.log2(len(out)))
 
 
$$
LANGUAGE plpython3u;
 
 
DROP AGGREGATE IF EXISTS bev3_norm(TEXT, TEXT);
CREATE AGGREGATE bev3_norm(TEXT, TEXT) (
  SFUNC=_state_bundle_entropy,
  STYPE=basket_tuple[],
  FINALFUNC=_final_bev3_norm,
  INITCOND='{}'
);


```

## 2 *Basket Revealed Entropy (BRE)*

The BRE method (formula 3 in the paper) from:
* *Guidotti, R., Coscia, M., Pedreschi, D. & Pennacchioli, D. (2015), ‘Behavioral entropy and profitability in retail’, Proceedings of the 2015 IEEE International Conference on Data Science and Advanced Analytics, DSAA 2015 pp. 1–10.* 

is implemented as a custom postgres aggregrate function. The implementation (copy and paste into psql to install) is:
```
CREATE TYPE basket_tuple_with_minsup AS (
   basket_id       TEXT,
   item       TEXT,
   minsup NUMERIC
);
 
CREATE OR REPLACE FUNCTION _state_bundle_entropy_with_minsup( prev basket_tuple_with_minsup[], basket_id TEXT, item TEXT, minsup NUMERIC)
   RETURNS basket_tuple_with_minsup[] AS
$$
   SELECT array_append(prev, (basket_id, item,minsup)::basket_tuple_with_minsup);
$$
LANGUAGE 'sql' IMMUTABLE;

CREATE OR REPLACE FUNCTION _final_bre(list_in basket_tuple_with_minsup[])
   RETURNS NUMERIC AS
$$
 
import pandas as pd
import numpy as np
from mlxtend.preprocessing import TransactionEncoder
from collections import defaultdict
from mlxtend.frequent_patterns import fpgrowth
from collections import Counter
 
data = defaultdict(list)
for record in list_in:
    minsup = record['minsup']
    data[record['basket_id']].append( record['item'] )
 
dataset = [ v for k, v in data.items() ]
 
# Now we have the dataset in a python format
 
te = TransactionEncoder()
 
data_as_sets = [frozenset(d) for d in dataset]
 
symbols_and_cts = defaultdict(int)
 
# Cache the single itete = TransactionEncoder()
oht_ary = te.fit(dataset).transform(dataset, sparse=True)
sparse_df = pd.DataFrame.sparse.from_spmatrix(oht_ary, columns=te.columns_)
frequent_itemsets = fpgrowth(sparse_df, min_support=minsup, use_colnames=True)
 
data_as_sets = [frozenset(d) for d in dataset]
 
symbols_and_cts = defaultdict(int)
 
# Compute and cache the single item support
# Guidotti et. al. (incorrectly) compute lift as the product of all single item's (within the common basket's) support
lst = []
for x in data_as_sets:
   lst += list(x)
Counter(lst)
single_item_support = {k:v/len(data_as_sets) for k, v in Counter(lst).items()}
 
for basket in data_as_sets:
   intersect_len = 0
   D = []
 
   for i, x in enumerate(frequent_itemsets.itemsets.values):
 
       # Compute the length of intersection between the common pattern and the basket
       # Keep only the baskets with the longest intersection length
       if x <= basket:
           inter = len(basket.intersection(x))
           if inter == intersect_len:
               D.append(x)
           elif inter > intersect_len:
               intersect_len = inter
               D = [x]
 
   #Algorithm 2 in Guidotti et. al.
   # if there is no "common pattern" in the basket, the basket is forced to become a common pattern
   if len(D) == 0:
       symbols_and_cts[basket] += 1
 
   # Otherwise select the "common pattern" with the longest intersection lenght
   elif len(D) == 1:
       symbols_and_cts[D[0]] += 1
 
   # If there is more than one of these compute the (incorrect, but Guidotti version) of lift and take the lowest
   else:
       D2 = []
       lift_up = 999999
       for common_pattern in D:
           cp_lift = np.prod([ single_item_support[x] for x in common_pattern ])
           if cp_lift == lift_up:
               D2.append(common_pattern)
           elif cp_lift < lift_up:
               lift_up = cp_lift
               D2 = [common_pattern]
       # If no ties for lowest lift assign the support of this basket to this common pattern
       if len(D2) == 1:
           symbols_and_cts[D2[0]] += 1
       else:
           # Otherwise approtion the support of this basket across the remaining patterns
           for dv in D2:
               symbols_and_cts[dv] += 1/len(D2)
 
total_rbs_support = np.sum([v for k, v in symbols_and_cts.items()])
if len(symbols_and_cts) == 1: # totally predictable
   rtn = 0
else:
   rtn = -np.sum( [ (v/total_rbs_support)*np.log2(v/total_rbs_support) for k, v in symbols_and_cts.items() if not ( np.log2(v/total_rbs_support) == 0 and (v/total_rbs_support) == 0) ] ) / np.log2(len(symbols_and_cts))
 
return rtn
 
$$
LANGUAGE plpython3u;
 
 
DROP AGGREGATE IF EXISTS bre(TEXT, TEXT, NUMERIC);
CREATE AGGREGATE bre(TEXT, TEXT, NUMERIC) (
  SFUNC=_state_bundle_entropy_with_minsup,
  STYPE=basket_tuple_with_minsup[],
  FINALFUNC=_final_bre,
  INITCOND='{}'
);
 
```

## 3 *Item Level Entropy (IE)*

The Standard Entropy (formula 1 in the paper) method from:

* *Shannon, C. (1948), ‘A Mathematical Theory of Communication’, The Bell System Technical Jour-
nal 28(3), 379–423* 

is implemented as a custom postgres aggregrate function. The implementation (copy and paste into psql to install) is:

```
CREATE OR REPLACE FUNCTION _final_norm_entropy(TEXT[])
    RETURNS NUMERIC AS
$$
DECLARE
    cnt NUMERIC;
DECLARE
    rtn NUMERIC;
DECLARE
    cntd NUMERIC;
BEGIN
    cnt := COUNT(*) FROM unnest($1) val;
    cntd := COUNT(DISTINCT val) FROM unnest($1) val;
    IF cntd < 2 THEN
       RETURN 0;
    END IF;
    SELECT INTO rtn -SUM(p)
    FROM (
      SELECT ((count(*)/cnt) * log(2,count(*)/cnt)/log(2,cntd)) as p, val
      FROM unnest($1) val
      GROUP BY val
    ) a;
    RETURN rtn;
END;
$$
LANGUAGE 'plpgsql' IMMUTABLE;

DROP AGGREGATE IF EXISTS norm_entropy(TEXT);
CREATE AGGREGATE norm_entropy(TEXT) (
   SFUNC=array_append,
   STYPE=TEXT[],
   FINALFUNC=_final_norm_entropy,
   INITCOND='{}'
);


```

## 4 *Basket Level Entropy (BLE)*

The BLE method (formula 2 in the paper) is implemented as a custom postgres aggregrate function. The implementation (copy and paste into psql to install) is (requires the previous code to be run to define **basket_tuple** and **_state_bundle_entropy**):

```
CREATE OR REPLACE FUNCTION _final_joint_entropy(list_in basket_tuple[])
   RETURNS NUMERIC AS
$$
DECLARE
    rtn NUMERIC;

BEGIN
 SELECT INTO rtn norm_entropy(basket::TEXT)
 FROM (
	 SELECT basket_id, array_agg(DISTINCT item ORDER BY item) as basket
	 FROM unnest($1)  
	 GROUP BY 1
) x ;
RETURN rtn;
END;
$$
LANGUAGE 'plpgsql' IMMUTABLE;

DROP AGGREGATE IF EXISTS joint_entropy(TEXT, TEXT);
CREATE AGGREGATE joint_entropy(TEXT, TEXT) (
  SFUNC=_state_bundle_entropy,
  STYPE=basket_tuple[],
  FINALFUNC=_final_joint_entropy,
  INITCOND='{}'
);
```
"""